{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"3-2강 Data Loader(심화편).ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"mv-7ZDSy7eyB"},"source":["# 3. 데이터 불러오기(심화편)\n","\n","딥러닝을 포함한 머신러닝의 근원은 데이터다. 따라서 데이터의 수집, 가공, 사용 방법에 따라 모델 성능이 크게 달라질 수 있으며 데이터의 형태는 매우 다양하기 때문에 데이터를 잘 불러오는 것은 가장 중요한 단계 중 하나다."]},{"cell_type":"markdown","metadata":{"id":"D0UgOCTE7eyL"},"source":["## 3.4 커스텀 데이터 + 커스텀 전처리\n","\n","이 번에는 텐서 생성 부분에서 이미지 전처리를 진행한다."]},{"cell_type":"code","metadata":{"id":"D36c4wrK7eyM","executionInfo":{"status":"ok","timestamp":1648027197941,"user_tz":-540,"elapsed":4953,"user":{"displayName":"JungYeon Heo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09714691475382312558"}}},"source":["import torch\n","import torchvision.transforms as tr # 이미지 전처리 기능들을 제공하는 라이브러리\n","from torch.utils.data import DataLoader, Dataset # 데이터를 모델에 사용할 수 있도록 정리해 주는 라이브러리\n","import numpy as np # 넘파이 기본 라이브러리"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"v9nVhHCO7eyN","executionInfo":{"status":"ok","timestamp":1648027197943,"user_tz":-540,"elapsed":14,"user":{"displayName":"JungYeon Heo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09714691475382312558"}}},"source":["# 32x32 컬러 이미지와 라벨이 각각 100장이 있다고 가정하다.\n","# glob -> PIL, openCV ..\n","train_images = np.random.randint(256,size=(100,32,32,3)) # (이미지 수)x(너비)x(높이)x(채널 수)\n","train_labels = np.random.randint(2,size=(100,1)) # 라벨 수\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uzd0tSIy7eyN","executionInfo":{"status":"ok","timestamp":1648027336196,"user_tz":-540,"elapsed":486,"user":{"displayName":"JungYeon Heo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09714691475382312558"}}},"source":["# 3.3에서 사용한 양식을 그대로 사용하되 전처리 작업을 할 수 있도록 transform을 추가한다. \n","class MyDataset(Dataset):\n","    \n","    def __init__(self, x_data, y_data, transform=None):\n","        \n","        self.x_data = x_data # 넘파이 배열이 들어온다.\n","        self.y_data = y_data # 넘파이 배열이 들어온다.\n","        self.transform = transform\n","        self.len = len(y_data)\n","    \n","    def __getitem__(self, index):\n","        sample = self.x_data[index], self.y_data[index]\n","        \n","        if self.transform:\n","            sample = self.transform(sample) #self.transform이 None이 아니라면 전처리를 작업한다.\n","        \n","        return sample # 3.3과 다르게 넘파이 배열로 출력 되는 것에 유의 하도록 한다.\n","    \n","    def __len__(self):\n","        return self.len       "],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"j6XlSNsi7eyO","executionInfo":{"status":"ok","timestamp":1648027338815,"user_tz":-540,"elapsed":296,"user":{"displayName":"JungYeon Heo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09714691475382312558"}}},"source":["# 전처리 기술을 직접 만들어 보자.\n","# 이 때 위 기본 양식과 같이 사용하기 위해 call 함수를 사용한다.\n","# def __call__ 내의 원하는 전처리 작업을 프로그래밍 할 수 있다.\n","\n","# 1. 텐서 변환\n","class ToTensor:\n","    def __call__(self, sample):\n","        inputs, labels = sample\n","        inputs = torch.FloatTensor(inputs) # 텐서로 변환\n","        inputs = inputs.permute(2,0,1) # 크기 변환\n","        return inputs, torch.LongTensor(labels) # 텐서로 변환\n","\n","# 2. 선형식    \n","class LinearTensor:\n","    \n","    def __init__(self, slope=1, bias=0):\n","        self.slope = slope\n","        self.bias = bias     \n","        \n","    def __call__(self, sample):\n","        inputs, labels = sample\n","        inputs = self.slope*inputs + self.bias # ax+b 계산하기\n","        return inputs, labels \n","\n","# ..... \n","# 추가로 계속 원하는 전처리를 정의하자.\n","# ..... "],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"KqlNPurj7eyO","executionInfo":{"status":"ok","timestamp":1648027341450,"user_tz":-540,"elapsed":8,"user":{"displayName":"JungYeon Heo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09714691475382312558"}}},"source":["trans = tr.Compose([ToTensor(),LinearTensor(2,5)]) # 텐서 변환 후 선형식 2x+5 연산\n","dataset1 = MyDataset(train_images,train_labels, transform=trans)\n","train_loader1 = DataLoader(dataset1, batch_size=10, shuffle=True)\n","\n","# ToTensor()와 tr.ToTensor()의 차이\n","# 앞 서 사용한 tr.ToTensor()는 import torchvision.transforms as tr를 이용한 파이토치 메소드를 이용한 것이고\n","# ToTensor()는 위에서 정의 된 메소드를 사용한 것이다."],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"9rQ1xcTK7eyO","outputId":"6214ab2e-2f90-431b-a747-4493c9a82ec5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648027346338,"user_tz":-540,"elapsed":337,"user":{"displayName":"JungYeon Heo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09714691475382312558"}}},"source":["dataiter1 = iter(train_loader1)\n","images1, labels1 = dataiter1.next()\n","print(images1.size()) # 배치 및 이미지 크기 확인"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([10, 3, 32, 32])\n"]}]},{"cell_type":"markdown","metadata":{"id":"Z5N_eyyQ7eyQ"},"source":["## 3.5 커스텀 데이터 + torchvision.transforms 전처리"]},{"cell_type":"code","metadata":{"id":"QLRWLT8F7eyQ","executionInfo":{"status":"ok","timestamp":1648027755866,"user_tz":-540,"elapsed":325,"user":{"displayName":"JungYeon Heo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09714691475382312558"}}},"source":["# torchvision.transforms에서 제공하는 전처리 기술을 사용한다.\n","# torchvision.transforms은 입력 이미지가 일반적으로 PILImage 타입이나 텐서일 경우에 동작한다.\n","# 현재 데이터는 넘파이 배열이다. 따라서 텐서 변환 후 tr.ToPILImage()을 이용하여 PILImage 타입으로 만들어 준다.\n","# __call__을 이용한 기본 구조는 동일하다.\n","\n","class MyTransform:\n","    \n","    def __call__(self, sample):\n","        inputs, labels = sample\n","        inputs = torch.FloatTensor(inputs)\n","        inputs = inputs.permute(2,0,1)\n","        labels = torch.FloatTensor(labels)\n","\n","        transf = tr.Compose([tr.ToPILImage(), tr.Resize(128),tr.ToTensor(),tr.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","        final_output = transf(inputs)      \n","        \n","        return final_output, labels  "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"saoSFgDT7eyR","executionInfo":{"status":"ok","timestamp":1648027760151,"user_tz":-540,"elapsed":519,"user":{"displayName":"JungYeon Heo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09714691475382312558"}}},"source":["dataset2 = MyDataset(train_images,train_labels, transform=MyTransform())\n","train_loader2 = DataLoader(dataset2, batch_size=15, shuffle=True)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6cKZ6llQ7eyR","executionInfo":{"status":"ok","timestamp":1648027760915,"user_tz":-540,"elapsed":382,"user":{"displayName":"JungYeon Heo","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09714691475382312558"}},"outputId":"6c38405e-4052-4909-a292-5c7768007364"},"source":["dataiter2 = iter(train_loader2)\n","images2, labels2 = dataiter2.next()\n","print(images2.size()) # 배치 및 이미지 크기 확인"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([15, 3, 128, 128])\n"]}]},{"cell_type":"code","metadata":{"id":"LumAqRvt-Hes"},"source":[""],"execution_count":null,"outputs":[]}]}